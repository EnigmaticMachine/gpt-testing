




ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Vectorstore | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesDocument LoadersText SplittersRetrieverVectorstoreMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsIndexesVectorstoreVectorstoreinfoPython GuideJS GuideThe most common type of index is one that creates numerical embeddings (with an Embedding Model) for each document. A vectorstore stores Documents and associated embeddings, and provides fast ways to look up relevant Documents by embeddings.PreviousRetrieverNextMemoryCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Models | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsLanguage ModelChat ModelText Embedding ModelPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsModelsOn this pageModelsinfoPython GuideJS GuideThis section of the documentation deals with different types of models that are used in LangChain.
On this page we will go over the model types at a high level,
but we have individual pages for each model type.LLMsLarge Language Models (LLMs) are the first type of models we cover.
These models take a text string as input, and return a text string as output.Chat ModelsChat Models are the second type of models we cover.
These models are usually backed by a language model, but their APIs are more structured.
Specifically, these models take a list of Chat Messages as input, and return a Chat Message.Text Embedding ModelsThe third type of models we cover are text embedding models.
These models take text as input and return a list of floats.Go deeperâ€‹ğŸ“„ï¸ Language ModelPython GuideğŸ“„ï¸ Chat ModelPython GuideğŸ“„ï¸ Text Embedding ModelPython GuidePreviousDocumentNextLanguage ModelGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Evaluation | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesEvaluationOn this pageEvaluationinfoPython GuideThis section of documentation covers how we approach and think about evaluation in LangChain.
Both evaluation of internal chains/agents, but also how we would recommend people building on top of LangChain approach evaluation.The Problemâ€‹It can be really hard to evaluate LangChain chains and agents.
There are two main reasons for this:# 1: Lack of dataYou generally don't have a ton of data to evaluate your chains/agents over before starting a project.
This is usually because Large Language Models (the core of most chains/agents) are terrific few-shot and zero shot learners,
meaning you are almost always able to get started on a particular task (text-to-SQL, question answering, etc) without
a large dataset of examples.
This is in stark contrast to traditional machine learning where you had to first collect a bunch of datapoints
before even getting started using a model.# 2: Lack of metricsMost chains/agents are performing tasks for which there are not very good metrics to evaluate performance.
For example, one of the most common use cases is generating text of some form.
Evaluating generated text is much more complicated than evaluating a classification prediction, or a numeric prediction.The Solutionâ€‹LangChain attempts to tackle both of those issues.
What we have so far are initial passes at solutions - we do not think we have a perfect solution.
So we very much welcome feedback, contributions, integrations, and thoughts on this.Here is what we have for each problem so far:# 1: Lack of dataWe have started LangChainDatasets a Community space on Hugging Face.
We intend this to be a collection of open source datasets for evaluating common chains and agents.
We have contributed five datasets of our own to start, but we highly intend this to be a community effort.
In order to contribute a dataset, you simply need to join the community and then you will be able to upload datasets.We're also aiming to make it as easy as possible for people to create their own datasets.
As a first pass at this, we've added a QAGenerationChain, which given a document comes up
with question-answer pairs that can be used to evaluate question-answering tasks over that document down the line.# 2: Lack of metricsWe have two solutions to the lack of metrics.The first solution is to use no metrics, and rather just rely on looking at results by eye to get a sense for how the chain/agent is performing.
To assist in this, we have developed (and will continue to develop) Tracing, a UI-based visualizer of your chain and agent runs.The second solution we recommend is to use Language Models themselves to evaluate outputs.
For this we have a few different chains and prompts aimed at tackling this issue.PreviousExtractionNextSummarizationThe ProblemThe SolutionCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Retriever | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesDocument LoadersText SplittersRetrieverVectorstoreMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsIndexesRetrieverRetrieverinfoPython GuideJS GuideA way of storing data such that it can be queried by a language model. The only interface this object must expose is a get_relevant_texts method which takes in a string and returns a list of Documents.PreviousText SplittersNextVectorstoreCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Tool | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsToolToolkitAgentAgent ExecutorUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsAgentsToolToolinfoPython GuideJS GuideA specific abstraction around a function that makes it easy for a language model to interact with it. Specificlaly, the interface of a tool has a single text input and a single text output.PreviousAgentsNextToolkitCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









LLMChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsChainLLMChainIndex-related chainsPrompt SelectorAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsChainsLLMChainLLMChainA LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.PreviousChainNextIndex-related chainsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Indexes | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesDocument LoadersText SplittersRetrieverVectorstoreMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsIndexesOn this pageIndexesinfoPython GuideJS GuideIndexes refer to ways to structure documents so that LLMs can best interact with them.
This module contains utility functions for working with documents, different types of indexes, and then examples for using those indexes in chains.The most common way that indexes are used in chains is in a "retrieval" step.
This step refers to taking a user's query and returning the most relevant documents.
We draw this distinction because (1) an index can be used for other things besides retrieval, and (2) retrieval can use other logic besides an index to find relevant documents.
We therefor have a concept of a "Retriever" interface - this is the interface that most chains work with.Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving unstructured data (like text documents).
For interacting with structured data (SQL tables, etc) or APIs, please see the corresponding use case sections for links to relevant functionality.
The primary index and retrieval types supported by LangChain are currently centered around vector databases, and therefore
a lot of the functionality we dive deep on those topics.Document LoadersClasses responsible for loading documents from various sources.Text SplittersClasses responsible for splitting text into smaller chunks.VectorStoresThe most common type of index. One that relies on embeddings.RetrieversInterface for fetching relevant documents to combine with language models.Go deeperâ€‹ğŸ“„ï¸ Document LoadersPython GuideğŸ“„ï¸ Text SplittersPython GuideğŸ“„ï¸ RetrieverPython GuideğŸ“„ï¸ VectorstorePython GuidePreviousOutput ParserNextDocument LoadersGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Chain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsChainLLMChainIndex-related chainsPrompt SelectorAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsChainsChainChainA chain is just an end-to-end wrapper around multiple individual components.PreviousChainsNextLLMChainCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Memory | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChat Message HistoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsMemoryOn this pageMemoryinfoPython GuideJS GuideMemory is the concept of storing and retrieving data in the process of a conversation. There are two main methods:Based on input, fetch any relevant pieces of dataBased on the input and output, update state accordinglyThere are two main types of memory: short term and long term.Short term memory generally refers to how to pass data in the context of a singular conversation (generally is previous ChatMessages or summaries of them).Long term memory deals with how to fetch and update information between conversations.Go deeperâ€‹ğŸ“„ï¸ Chat Message HistoryThe primary interface with language models at the moment in through a chat interface. The ChatMessageHistory class is responsible for remembering all previous chat interactions. These can then be passed directly back into the model, summarized in some way, or some combination.PreviousVectorstoreNextChat Message HistoryGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Language Model | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsLanguage ModelChat ModelText Embedding ModelPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsModelsLanguage ModelLanguage ModelinfoPython GuideJS GuideA language model takes text as an input and returns text as an output.PreviousModelsNextChat ModelCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Text Embedding Model | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsLanguage ModelChat ModelText Embedding ModelPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsModelsText Embedding ModelText Embedding ModelinfoPython GuideJS GuideA text embedding model takes a piece of text as input and numerical representation of that text in the form of a list of floats.PreviousChat ModelNextPromptsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Querying Tabular Data | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesQuerying Tabular DataOn this pageQuerying Tabular DatainfoPython GuideJS GuideLots of data and information is stored in tabular data, whether it be csvs, excel sheets, or SQL tables.
This page covers all resources available in LangChain for working with data in this format.Document Loadingâ€‹If you have text data stored in a tabular format, you may want to load the data into a Document and then index it as you would
other text/unstructured data. For this, you should use a document loader like the CSVLoader
and then you should create an Index over that data, and query it that way.Queryingâ€‹If you have more numeric tabular data, or have a large amount of data and don't want to index it, you can also use a language model to interact with it directly.Chainsâ€‹If you are just getting started, and you have relatively small/simple tabular data, you should get started with chains.
Chains are a sequence of predetermined steps, so they are good to get started with as they give you more control and let you
understand what is happening better.Agentsâ€‹Agents are more complex, and involve multiple queries to the LLM to understand what to do.
The downside of agents are that you have less control. The upside is that they are more powerful,
which allows you to use them on larger databases and more complex schemas.PreviousChatbotsNextInteracting with APIsDocument LoadingQueryingChainsAgentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Use Cases | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesUse CasesThis section highlights different end-to-end use cases that LangChain can help with. For each use case, we not only motivate the use case but also discuss which components are most helpful for solving that use case.ğŸ“„ï¸ Personal AssistantsPython GuideğŸ“„ï¸ Question Answering Over DocsPython GuideğŸ“„ï¸ ChatbotsPython GuideğŸ“„ï¸ Querying Tabular DataPython GuideğŸ“„ï¸ Interacting with APIsPython GuideğŸ“„ï¸ ExtractionPython GuideğŸ“„ï¸ EvaluationPython GuideğŸ“„ï¸ SummarizationPython GuidePreviousAgent ExecutorNextPersonal AssistantsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Chains | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsChainLLMChainIndex-related chainsPrompt SelectorAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsChainsOn this pageChainsinfoPython GuideJS GuideChains is an incredibly generic concept which returns to a sequence of modular components (or other chains) combined in a particular way to accomplish a common use case.The most commonly used type of chain is an LLMChain, which combines a PromptTemplate, a Model, and Guardrails to take user input, format it accordingly, pass it to the model and get a response, and then validate and fix (if necessary) the model output.Go deeperâ€‹ğŸ“„ï¸ ChainA chain is just an end-to-end wrapper around multiple individual components.ğŸ“„ï¸ LLMChainA LLMChain is the most common type of chain. It consists of a PromptTemplate, a model (either an LLM or a ChatModel), and an optional output parser. This chain takes multiple input variables, uses the PromptTemplate to format them into a prompt. It then passes that to the model. Finally, it uses the OutputParser (if provided) to parse the output of the LLM into a final format.ğŸ“„ï¸ Index-related chainsPython GuideğŸ“„ï¸ Prompt SelectorOne of the goals of chains in LangChain is to enable people to get started with a particular use case as quickly as possible. A big part of this is having good prompts.PreviousChat Message HistoryNextChainGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Prompt Value | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsPrompt ValuePrompt TemplateExample SelectorsOutput ParserIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsPromptsPrompt ValuePrompt ValueA â€œpromptâ€ refers to what is passed to the underlying model. The main abstractions have for prompt in LangChain so for all deal with text data. For other data types (images, audio) we are working on adding abstractions but do not yet have them. Different models may expect different data formats. Where possible, we want to allow for the same prompt to be used in different model types. For that reason, we have a concept of a PromptValue. This is a class which exposes methods to be converted to the exact input types that each model type expects (text or ChatMessages for now)PreviousPromptsNextPrompt TemplateCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Prompts | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsPrompt ValuePrompt TemplateExample SelectorsOutput ParserIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsPromptsOn this pagePromptsinfoPython GuideJS GuideThe new way of programming models is through prompts.
A "prompt" refers to the input to the model.
This input is rarely hard coded, but rather is often constructed from multiple components.
A PromptTemplate is responsible for the construction of this input.
LangChain provides several classes and functions to make constructing and working with prompts easy.This section of documentation is split into four sections:PromptValueThe class representing an input to a model.Prompt TemplatesThe class in charge of constructing a PromptValue.Example SelectorsOften times it is useful to include examples in prompts.
These examples can be hardcoded, but it is often more powerful if they are dynamically selected.Output ParsersLanguage models (and Chat Models) output text.
But many times you may want to get more structured information than just text back.
This is where output parsers come in.
Output Parsers are responsible for (1) instructing the model how output should be formatted,
(2) parsing output into the desired formatting (including retrying if necessary).Go deeperâ€‹ğŸ“„ï¸ Prompt ValueA â€œpromptâ€ refers to what is passed to the underlying model. The main abstractions have for prompt in LangChain so for all deal with text data. For other data types (images, audio) we are working on adding abstractions but do not yet have them.ğŸ“„ï¸ Prompt TemplatePython GuideğŸ“„ï¸ Example SelectorsPython GuideğŸ“„ï¸ Output ParserPython GuidePreviousText Embedding ModelNextPrompt ValueGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Prompt Template | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsPrompt ValuePrompt TemplateExample SelectorsOutput ParserIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsPromptsPrompt TemplatePrompt TemplateinfoPython GuideJS GuideA PromptValue is what is eventually passed to the model. Most of the time, this value is not hardcoded but is rather dynamically created based on a combination of user input, other non-static information (often coming from multiple sources), and a fixed template string. We call the object responsible  for creating the PromptValue a PromptTemplate. This object exposes a method for taking in input variables and returning a PromptValue.PreviousPrompt ValueNextExample SelectorsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Toolkit | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsToolToolkitAgentAgent ExecutorUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsAgentsToolkitToolkitinfoPython GuideJS GuideGroups of tools that can be used/are necessary to solve a particular problem.PreviousToolNextAgentCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Examples | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaTextChatMessagesExamplesDocumentModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsSchemaExamplesExamplesExamples are input/output pairs that represent inputs to a function and then expected output. They can be used in both training and evaluation of models.These can be inputs/outputs for a model or for a chain. Both types of examples serve a different purpose. Examples for a model can be used to finetune a model. Examples for a chain can be used to evaluate the end-to-end chain, or maybe even train a model to replace that whole chain.PreviousChatMessagesNextDocumentCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ChatMessages | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaTextChatMessagesExamplesDocumentModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsSchemaChatMessagesOn this pageChatMessagesThe primary interface through which end users interact with these is a chat interface. For this reason, some model providers even started providing access to the underlying API in a way that expects chat messages. These messages have a content field (which is usually text) and are associated with a user. Right now the supported users are System, Human, and AI.SystemChatMessageâ€‹A chat message representing information that should be instructions to the AI system.HumanChatMessageâ€‹A chat message representing information coming from a human interacting with the AI system.AIChatMessageâ€‹A chat message representing information coming from the AI system.PreviousTextNextExamplesSystemChatMessageHumanChatMessageAIChatMessageCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Index-related chains | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsChainLLMChainIndex-related chainsPrompt SelectorAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsChainsIndex-related chainsOn this pageIndex-related chainsinfoPython GuideJS GuideThis category of chains are used for interacting with indexes. The purpose these chains is to combine your own data (stored in the indexes) with LLMs. The best example of this is question answering over your own documents.A big part of this is understanding how to pass multiple documents to the language model.
There are a few different methods, or chains, for doing so. LangChain supports four of the more common ones - and
we are actively looking to include more, so if you have any ideas please reach out! Note that there is not
one best method - the decision of which one to use is often very context specific. In order from simplest to
most complex:Stuffingâ€‹Stuffing is the simplest method, whereby you simply stuff all the related data into the prompt as context
to pass to the language model. This is implemented in LangChain as the StuffDocumentsChain.Pros: Only makes a single call to the LLM. When generating text, the LLM has access to all the data at once.Cons: Most LLMs have a context length, and for large documents (or many documents) this will not work as it will result in a prompt larger than the context length.The main downside of this method is that it only works on smaller pieces of data. Once you are working
with many pieces of data, this approach is no longer feasible. The next two approaches are designed to help deal with that.Map Reduceâ€‹This method involves running an initial prompt on each chunk of data (for summarization tasks, this
could be a summary of that chunk; for question-answering tasks, it could be an answer based solely on that chunk).
Then a different prompt is run to combine all the initial outputs. This is implemented in the LangChain as the MapReduceDocumentsChain.Pros: Can scale to larger documents (and more documents) than StuffDocumentsChain. The calls to the LLM on individual documents are independent and can therefore be parallelized.Cons: Requires many more calls to the LLM than StuffDocumentsChain. Loses some information during the final combined call.Refineâ€‹This method involves running an initial prompt on the first chunk of data, generating some output.
For the remaining documents, that output is passed in, along with the next document,
asking the LLM to refine the output based on the new document. Pros: Can pull in more relevant context, and may be less lossy than MapReduceDocumentsChain.Cons: Requires many more calls to the LLM than StuffDocumentsChain. The calls are also NOT independent, meaning they cannot be paralleled like MapReduceDocumentsChain. There is also some potential dependencies on the ordering of the documents.Map-Rerankâ€‹This method involves running an initial prompt on each chunk of data, that not only tries to complete a
task but also gives a score for how certain it is in its answer. The responses are then
ranked according to this score, and the highest score is returned.Pros: Similar pros as MapReduceDocumentsChain. Requires fewer calls, compared to MapReduceDocumentsChain.Cons: Cannot combine information between documents. This means it is most useful when you expect there to be a single simple answer in a single document.PreviousLLMChainNextPrompt SelectorStuffingMap ReduceRefineMap-RerankCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Schema | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaTextChatMessagesExamplesDocumentModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsSchemaSchemaThis section covers the basic data types and schemas that are used throughout the codebase.ğŸ“„ï¸ TextWhen working with language models, the primary interface through which you can interact with them is through text. As an over simplification, a lot of models are "text in, text out". Therefor, a lot of the interfaces in LangChain are centered around text.ğŸ“„ï¸ ChatMessagesThe primary interface through which end users interact with these is a chat interface. For this reason, some model providers even started providing access to the underlying API in a way that expects chat messages. These messages have a content field (which is usually text) and are associated with a user. Right now the supported users are System, Human, and AI.ğŸ“„ï¸ ExamplesExamples are input/output pairs that represent inputs to a function and then expected output. They can be used in both training and evaluation of models.ğŸ“„ï¸ DocumentA piece of unstructured data. Consists of page_content (the content of the data) and metadata (auxiliary pieces of information describing attributes of the data).PreviousComponentsNextTextCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Agents | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsToolToolkitAgentAgent ExecutorUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsAgentsOn this pageAgentsinfoPython GuideJS GuideSome applications will require not just a predetermined chain of calls to LLMs/other tools,
but potentially an unknown chain that depends on the user's input.
In these types of chains, there is a â€œagentâ€ which has access to a suite of tools.
Depending on the user input, the agent can then decide which, if any, of these tools to call.We split the documentation into the following sections:ToolsHow language models interact with other resources.AgentsThe language model that drives decision making.ToolkitsSets of tools that when used together can accomplish a specific task.Agent ExecutorThe logic for running agents with tools.Go deeperâ€‹ğŸ“„ï¸ ToolPython GuideğŸ“„ï¸ ToolkitPython GuideğŸ“„ï¸ AgentPython GuideğŸ“„ï¸ Agent ExecutorPython GuidePreviousPrompt SelectorNextToolGo deeperCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Personal Assistants | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesPersonal AssistantsPersonal AssistantsinfoPython GuideJS GuidePersonal assistants are a perfect application to build because they combine both of the core value props of LangChain (action taking and personalized data). In order to build a personal assistant you should understand the following concepts:PromptTemplate - this will guide how your personal assistant acts. Are they sassy? Helpful? These can be used to give your personal assistant some character.Memory - your personal assistant should probably remember things. They should definitely be able to hold a conversation (short term memory) and they should probably have some concept of long term memory as well.Tools - your personal assistant will be differentiated by the tools you give it. What should it know how to do?Agent - your personal assistant will have to understand what actions it should take. Constructing the best agent possible will be important.Agent Executor - after you've got your tools and your agent, in order to put it into practice you'll need to set up an environment for the agent to use those tools. This is where the Agent Executor comes into play.PreviousUse CasesNextQuestion Answering Over DocsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Text Splitters | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesDocument LoadersText SplittersRetrieverVectorstoreMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsIndexesText SplittersText SplittersinfoPython GuideJS GuideOften times you want to split large text documents into smaller chunks to better work with language models. TextSplitters are responsible for splitting up a document into smaller documents.PreviousDocument LoadersNextRetrieverCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Chat Model | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsLanguage ModelChat ModelText Embedding ModelPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsModelsChat ModelChat ModelinfoPython GuideJS GuideA chat model takes a list of ChatMessages as an input and returns a ChatMessage.PreviousLanguage ModelNextText Embedding ModelCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Summarization | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesSummarizationSummarizationinfoPython GuideJS GuideA common use case is wanting to summarize long documents. This naturally runs into the context window limitations. Unlike in question-answering, you can't just do some semantic search hacks to only select the chunks of text most relevant to the question (because, in this case, there is no particular question - you want to summarize everything). So what do you do then?The most common way around this is to split the documents into chunks and then do summarization in a recursive manner. By this we mean you first summarize each chunk by itself, then you group the summaries into chunks and summarize each chunk of summaries, and continue doing that until only one is left.PreviousEvaluationCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Interacting with APIs | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesInteracting with APIsOn this pageInteracting with APIsinfoPython GuideJS GuideAPIs are powerful because they both allow you to take actions via them, but also they can allow you to query data through them. This page covers all resources available in LangChain for working with APIs.Chainsâ€‹If you are just getting started, and you have s relatively small/simple API, you should get started with chains.
Chains are a sequence of predetermined steps, so they are good to get started with as they give you more control and let you
understand what is happening better.Agentsâ€‹Agents are more complex, and involve multiple queries to the LLM to understand what to do.
The downside of agents are that you have less control. The upside is that they are more powerful,
which allows you to use them on larger or more complex APIs.PreviousQuerying Tabular DataNextExtractionChainsAgentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Document Loaders | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesDocument LoadersText SplittersRetrieverVectorstoreMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsIndexesDocument LoadersDocument LoadersinfoPython GuideJS GuideDocument Loaders are responsible for loading a list of Document objects.PreviousIndexesNextText SplittersCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Output Parser | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsPrompt ValuePrompt TemplateExample SelectorsOutput ParserIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsPromptsOutput ParserOutput ParserinfoPython GuideJS GuideOutput parsers are classes that help structure language model responses. There are two main methods an output parser must implement:get_format_instructions() -> str: A method which returns a string containing instructions for how the output of a language model should be formatted.parse(str) -> Any: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.And then one optional one:parse_with_prompt(str) -> Any: A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.PreviousExample SelectorsNextIndexesCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Text | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaTextChatMessagesExamplesDocumentModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsSchemaTextTextWhen working with language models, the primary interface through which you can interact with them is through text. As an over simplification, a lot of models are "text in, text out". Therefor, a lot of the interfaces in LangChain are centered around text.PreviousSchemaNextChatMessagesCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Chat Message History | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChat Message HistoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsMemoryChat Message HistoryChat Message HistoryThe primary interface with language models at the moment in through a chat interface. The ChatMessageHistory class is responsible for remembering all previous chat interactions. These can then be passed directly back into the model, summarized in some way, or some combination.ChatMessageHistory exposes two methods and one attribute. The two methods it exposes are add_user_message and add_ai_message, used for storing messages from users and responses from the AI accordingly. The attribute it exposes is a messages attribute, used for accessing all previous messages.PreviousMemoryNextChainsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Example Selectors | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsPrompt ValuePrompt TemplateExample SelectorsOutput ParserIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsPromptsExample SelectorsExample SelectorsinfoPython GuideJS GuideOften times it is useful to include in the prompt examples in a prompt. These examples can be hardcoded, but it is often more powerful if they are dynamically selected. ExampleSelectors are objects that take in user input and then return a list of examples to use.PreviousPrompt TemplateNextOutput ParserCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Extraction | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesExtractionExtractioninfoPython GuideLanguage models are actually great at extracting structured information from unstructured text. This is useful because a lot of information is stored as text, but in order to make it most usable downstream it is often convinient to convert it to a structured format.The most useful concept to understand here is the idea of OutputParsers. OutputParsers are responsible for specifying the schema a language model should respond in, and then parsing their raw-text output into that structured format. The way you would use these to do extraction is that you would define the schema of the information you want to extract in an OutputParser. You would then create a PromptTemplate that takes in a raw text blob, with instructions to extract information in the specified format.PreviousInteracting with APIsNextEvaluationCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Prompt Selector | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsChainLLMChainIndex-related chainsPrompt SelectorAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsChainsPrompt SelectorPrompt SelectorOne of the goals of chains in LangChain is to enable people to get started with a particular use case as quickly as possible. A big part of this is having good prompts.The problem is that a prompt that works for one model may not work as well for another model. We want to enable chains to work well for all types of models. Therefore, rather than hardcoding a default prompt to use in chains, we have the concept of a PromptSelector. This PromptSelector is responsible for choosing a default prompt depending on the model passed in.The most common use case of PromptSelectors is to set different default prompts for LLMs vs Chat Models. However, this can also be used to set different default prompts for different model providers, should one choose.PreviousIndex-related chainsNextAgentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Agent Executor | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsToolToolkitAgentAgent ExecutorUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsAgentsAgent ExecutorAgent ExecutorinfoPython GuideJS GuideAn Agent Executor is an Agent and set of Tools. The agent executor is responsible for calling the agent, getting back and action and action input, calling the tool that the action references with the corresponding input, getting the output of the tool, and then passing all that information back into the Agent to get the next action it should takePreviousAgentNextUse CasesCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Document | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaTextChatMessagesExamplesDocumentModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsSchemaDocumentDocumentA piece of unstructured data. Consists of page_content (the content of the data) and metadata (auxiliary pieces of information describing attributes of the data).PreviousExamplesNextModelsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Question Answering Over Documents | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesQuestion Answering Over DocsOn this pageQuestion Answering Over DocumentsinfoPython GuideJS GuideAlthough LLMs are powerful, they do not know about information they were not trained on. If you want to use an LLM to answer questions about documents it was not trained on, you have to give it information about those documents. The most common way to do this is through "retrieval augmented generation".The idea of retrieval augmented generation is that when given a question you first do a retrieval step to fetch any relevant documents. You then pass those documents, along with the original question, to the language model and have it generate a response. In order to do this, however, you first have to have your documents in a format where they can be queried in such a manner. This page goes over the high level ideas between those two steps: (1) ingestion of documents into a queriable format, and then (2) the retrieval augmented generation chain.Ingestionâ€‹In order use a language model to interact with your data, you first have to get in a suitable format. That format would be an Index. By putting data into an Index, you make it easy for any downstream steps to interact with it.There are several types of indexes, but by far the most common one is a Vectorstore. Ingesting documents into a vectorstore can be done with the following steps:Load documents (using a Document Loader)Split documents (using a Text Splitter)Create embeddings for documents (using a Text Embedding Model)Store documents and embeddings in a vectorstoreGenerationâ€‹Now that we have an Index, how do we use this to do generation? This can be broken into the following steps:Receive user questionLookup documents in the index relevant to the questionConstruct a PromptValue from the question and any relevant documents (using a PromptTemplate).Pass the PromptValue to a modelGet back the result and return to the user.PreviousPersonal AssistantsNextChatbotsIngestionGenerationCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Agent | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsToolToolkitAgentAgent ExecutorUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsAgentsAgentAgentinfoPython GuideJS GuideAn Agent is a wrapper around a model, which takes in user input and returns a response corresponding to an â€œactionâ€ to take and a corresponding â€œaction inputâ€.PreviousToolkitNextAgent ExecutorCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Components | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationComponentsComponentsIn this section we first cover some underlying schema abstractions, before diving into the six main components of LangChain.ğŸ—ƒï¸ Schema4 itemsğŸ—ƒï¸ Models3 itemsğŸ—ƒï¸ Prompts4 itemsğŸ—ƒï¸ Indexes4 itemsğŸ—ƒï¸ Memory1 itemsğŸ—ƒï¸ Chains4 itemsğŸ—ƒï¸ Agents4 itemsPreviousIntroductionNextSchemaCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









Chatbots | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationUse CasesChatbotsChatbotsinfoPython GuideChatGPT took the world by storm by exposing a powerful language model with a new interface - chat. There are several components that go into building a chatbot.The model - you can construct a chatbot from a normal language model or a Chat Model. The important thing to remember is that even if you are using a Chat Model, the API itself is stateless, meaning it won't remember previous interactions - you have to pass them in.PromptTemplate - this will guide how your chatbot acts. Are they sassy? Helpful? These can be used to give your chatbot some character.Memory - as mentioned above, the models themselves are stateless. Memory brings some concept of state to the table, allowing it remember previous interactionsChatbots are often very powerful and more differentiated when combined with other sources of data. The same techniques that underpin "Question Answering Over Docs" can also be used here to give your chatbot access to that data.PreviousQuestion Answering Over DocsNextQuerying Tabular DataCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.









ğŸ¦œï¸ğŸ”— LangChain | ğŸ¦œï¸ğŸ”— LangChain





Skip to main contentğŸ¦œï¸ğŸ”— LangChainConceptsPython DocsJS/TS DocsIntroductionComponentsSchemaModelsPromptsIndexesMemoryChainsAgentsUse CasesPersonal AssistantsQuestion Answering Over DocsChatbotsQuerying Tabular DataInteracting with APIsExtractionEvaluationSummarizationIntroductionğŸ¦œï¸ğŸ”— LangChainLangChain is a framework for developing applications powered by language models.
We believe that the most powerful and differentiated applications will not only call out to a language model via an api, but will also:Be data-aware: connect a language model to other sources of dataBe agentic: Allow a language model to interact with its environmentAs such, the LangChain framework is designed with the objective in mind to enable those types of applications.There are two main value props the LangChain framework provides:Components: LangChain provides modular abstractions for the components neccessary to work with language models. LangChain also has collections of implementations for all these abstractions. The components are designed to be easy to use, regardless of whether you are using the rest of the LangChain framework or not.Use-Case Specific Chains: Chains can be thought of as assembling these components in particular ways in order to best accomplish a particular use case. These are intended to be a higher level interface through which people can easily get started with a specific use case. These chains are also designed to be customizable.Accordingly, we split the following documentation into those two value props. In this documentation, we go over components and use cases at high level and in a language-agnostic way. For language-specific ways of using these components and tackling these use cases, please see the language-specific sections linked at the top of the page.NextComponentsCommunityDiscordTwitterGitHubPythonJS/TSMoreHomepageBlogCopyright Â© 2023 LangChain, Inc.



